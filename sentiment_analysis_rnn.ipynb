{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cdbe3408-b252-41bc-b605-537662925b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cb3daf-484a-44e7-a029-d927f6b14ea5",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8c695e-e0e1-4875-b8c2-5222ebc3a140",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e7d85e7c-0551-47bd-92c8-c613a4cd7470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219</td>\n",
       "      <td>Nikmati cicilan 0% hingga 12 bulan untuk pemes...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>209</td>\n",
       "      <td>Kue-kue yang disajikan bikin saya bernostalgia...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436</td>\n",
       "      <td>Ibu pernah bekerja di grab indonesia</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>Paling suka banget makan siang di sini ayam sa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>Pelayanan bus DAMRI sangat baik</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>502</td>\n",
       "      <td>Saya sudah sering kali datang menikmati makana...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>268</td>\n",
       "      <td>Banyak orang yang kurang suka untuk berobat ke...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>282</td>\n",
       "      <td>Pelayanan baik, tempat parkir cukup luas, kebu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>407</td>\n",
       "      <td>Demi apa pun tes cpns bikin macet, sialannnnnnn</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>768</td>\n",
       "      <td>Menunggu makanannya lama banget, waitressnya g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text     label\n",
       "0    219  Nikmati cicilan 0% hingga 12 bulan untuk pemes...   neutral\n",
       "1    209  Kue-kue yang disajikan bikin saya bernostalgia...  positive\n",
       "2    436               Ibu pernah bekerja di grab indonesia   neutral\n",
       "3    394  Paling suka banget makan siang di sini ayam sa...  positive\n",
       "4    592                    Pelayanan bus DAMRI sangat baik  positive\n",
       "..   ...                                                ...       ...\n",
       "995  502  Saya sudah sering kali datang menikmati makana...  positive\n",
       "996  268  Banyak orang yang kurang suka untuk berobat ke...  negative\n",
       "997  282  Pelayanan baik, tempat parkir cukup luas, kebu...  positive\n",
       "998  407    Demi apa pun tes cpns bikin macet, sialannnnnnn  negative\n",
       "999  768  Menunggu makanannya lama banget, waitressnya g...  negative\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_valid = pd.read_csv(\"valid.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df =  pd.concat([df_train, df_valid, df_test], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d20c1b49-1cd3-49f3-9896-d491ca189172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "negative    383\n",
       "positive    378\n",
       "neutral     239\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148207a-d29b-4c31-86b5-9e50501579db",
   "metadata": {},
   "source": [
    "# Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ddb201e7-db17-4c68-880d-f266f957d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(sent):\n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d2d8592-9c10-4a68-a775-e3ed89ccbb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219</td>\n",
       "      <td>Nikmati cicilan 0% hingga 12 bulan untuk pemes...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>nikmati cicilan 0  hingga 12 bulan untuk pemes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>209</td>\n",
       "      <td>Kue-kue yang disajikan bikin saya bernostalgia...</td>\n",
       "      <td>positive</td>\n",
       "      <td>kue kue yang disajikan bikin saya bernostalgia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436</td>\n",
       "      <td>Ibu pernah bekerja di grab indonesia</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ibu pernah bekerja di grab indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>Paling suka banget makan siang di sini ayam sa...</td>\n",
       "      <td>positive</td>\n",
       "      <td>paling suka banget makan siang di sini ayam sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592</td>\n",
       "      <td>Pelayanan bus DAMRI sangat baik</td>\n",
       "      <td>positive</td>\n",
       "      <td>pelayanan bus damri sangat baik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text     label  \\\n",
       "0  219  Nikmati cicilan 0% hingga 12 bulan untuk pemes...   neutral   \n",
       "1  209  Kue-kue yang disajikan bikin saya bernostalgia...  positive   \n",
       "2  436               Ibu pernah bekerja di grab indonesia   neutral   \n",
       "3  394  Paling suka banget makan siang di sini ayam sa...  positive   \n",
       "4  592                    Pelayanan bus DAMRI sangat baik  positive   \n",
       "\n",
       "                                          text_clean  \n",
       "0  nikmati cicilan 0  hingga 12 bulan untuk pemes...  \n",
       "1  kue kue yang disajikan bikin saya bernostalgia...  \n",
       "2               ibu pernah bekerja di grab indonesia  \n",
       "3  paling suka banget makan siang di sini ayam sa...  \n",
       "4                    pelayanan bus damri sangat baik  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_clean'] = df.text.apply(cleansing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e58ac9c-0e28-488c-be69-d98bf6ec2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos: 378, Neu: 239, Neg: 383\n",
      "Total data: 1000\n"
     ]
    }
   ],
   "source": [
    "neg = df.loc[df.label == 'negative'].text_clean.tolist()\n",
    "neu = df.loc[df.label == 'neutral'].text_clean.tolist()\n",
    "pos = df.loc[df.label == 'positive'].text_clean.tolist()\n",
    "\n",
    "neg_label = df.loc[df.label == 'negative'].label.tolist()\n",
    "neu_label = df.loc[df.label == 'neutral'].label.tolist()\n",
    "pos_label = df.loc[df.label == 'positive'].label.tolist()\n",
    "\n",
    "total_data = pos + neu + neg\n",
    "labels = pos_label + neu_label + neg_label\n",
    "\n",
    "print(\"Pos: %s, Neu: %s, Neg: %s\" % (len(pos), len(neu), len(neg)))\n",
    "print(\"Total data: %s\" % len(total_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6dda46-6f3e-4fb5-8097-2a903dea9d71",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae1a767d-9fcb-473e-8d6e-7eca6358b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "767feaa4-8500-4bf7-8241-e6bb9c6dd900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "max_features = 100000\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ', lower=True)\n",
    "tokenizer.fit_on_texts(total_data)\n",
    "\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"tokenizer.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1335dd31-0e89-432e-86de-0535407d9e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(total_data)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "maxlen = max(len(x) for x in X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa050df6-7474-41cd-9b3d-5611320d1c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_pad_sequences.pickle has created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   49,   14,  104],\n",
       "       [   0,    0,    0, ...,    7,   12,  564],\n",
       "       [   0,    0,    0, ..., 1876,   16,  103],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  918,   14, 1769],\n",
       "       [   0,    0,    0, ...,  111,  185, 4257],\n",
       "       [   0,    0,    0, ..., 4261,  120,  435]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(X)\n",
    "\n",
    "with open('x_pad_sequences.pickle','wb') as handle:\n",
    "    pickle.dump(X, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"x_pad_sequences.pickle has created!\")\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f157d4b9-f97d-4766-952e-038a59e7057e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_labels.pickle has created!\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(labels)\n",
    "Y = Y.values\n",
    "\n",
    "with open('y_labels.pickle', 'wb') as handle:\n",
    "    pickle.dump(Y, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"y_labels.pickle has created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d26f8599-ec9e-4006-850c-4a5d2e2c432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1   2   3   4   5   6   7    8   9   ...    67    68    69    70  \\\n",
      "0     0   0   0   0   0   0   0   0    0   0  ...    17   919   389    32   \n",
      "1     0   0   0   0   0   0   0   0    0   0  ...  1874     9  1875    41   \n",
      "2     0   0   0   0   0   0   0   0    0   0  ...     0     0     0     0   \n",
      "3     0   0   0   0   0   0   0   0    0   0  ...    20   755  1229     2   \n",
      "4    77  28  12  20  79  80  67   3  756  67  ...   352  1231   220    97   \n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ...   ...   ...   ...   ...   \n",
      "995   0   0   0   0   0   0   0   0    0   0  ...     3   271    48   117   \n",
      "996   0   0   0   0   0   0   0   0    0   0  ...  1171     2   385    91   \n",
      "997   0   0   0   0   0   0   0   0    0   0  ...   101  4253  4254  4255   \n",
      "998   0   0   0   0   0   0   0   0    0   0  ...     0     0   633    98   \n",
      "999   0   0   0   0   0   0   0   0    0   0  ...    50   778    71    65   \n",
      "\n",
      "       71    72    73    74    75    76  \n",
      "0    1226     7     3    49    14   104  \n",
      "1      10    42    51     7    12   564  \n",
      "2       0    61   754  1876    16   103  \n",
      "3     105    23   350   351     3   230  \n",
      "4     186    48    12    13     8    45  \n",
      "..    ...   ...   ...   ...   ...   ...  \n",
      "995   189  4247     3   189  4248   194  \n",
      "996   701   478    81   535   108   120  \n",
      "997    19  4256  1507   918    14  1769  \n",
      "998    71  1796  1627   111   185  4257  \n",
      "999     5   249     4  4261   120   435  \n",
      "\n",
      "[1000 rows x 77 columns]\n"
     ]
    }
   ],
   "source": [
    "df_array = pd.DataFrame(data=X)\n",
    "print(df_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c49aab8-37ec-4c7a-be13-ad337bb782f7",
   "metadata": {},
   "source": [
    "# Split traning and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79411e2c-9786-4ac5-9d02-5296d7741fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae82aa32-4b35-419d-915a-ecfac290e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"x_pad_sequences.pickle\", \"rb\")\n",
    "X = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10ca2f4e-3e42-44f1-ad11-382eb43b5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"y_labels.pickle\", \"rb\")\n",
    "Y = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c2442b4-f3ea-4c53-9c1c-091cb979bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4ebdc2-01b7-4c8e-bec5-7cdd3005759b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c1ed2a8-0b31-4904-a42e-f611e39831a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN, Activation\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7390b0de-b208-43fb-a80a-c74edfa136ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "units = 64\n",
    "\n",
    "max_features = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d157e66d-f97f-45d6-83d7-0fdabe4eadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <Sequential name=sequential_17, built=False>>\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_dim))\n",
    "model.add(SimpleRNN(units, dropout=0.2))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "sgd = optimizers.Adam(learning_rate= 0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary)\n",
    "\n",
    "adam = optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "da89c4de-84cd-4de9-adfb-903ad2935064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.4599 - loss: 1.0208 - val_accuracy: 0.5850 - val_loss: 0.8990\n",
      "Epoch 2/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.8512 - loss: 0.5620 - val_accuracy: 0.6750 - val_loss: 0.7655\n",
      "Epoch 3/10\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9791 - loss: 0.1511 - val_accuracy: 0.6000 - val_loss: 0.8792\n",
      "Epoch 3: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=10, validation_data = (X_test, y_test), verbose=1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "256e1a8d-ffe0-4d7f-9a40-53d172aba14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has created!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"API/model_of_rnn/model_rnn.keras\")\n",
    "print(\"Model has created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cee2c7-d968-4542-99d4-936c4061fbf0",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68821194-c629-4761-82ef-716dad60816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6be5f2c-b28c-4ced-bad6-abfcde573de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.47      0.49        73\n",
      "           1       0.47      0.48      0.48        54\n",
      "           2       0.76      0.82      0.79        73\n",
      "\n",
      "    accuracy                           0.60       200\n",
      "   macro avg       0.58      0.59      0.59       200\n",
      "weighted avg       0.59      0.60      0.60       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = predictions\n",
    "matrix_test = metrics.classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "print(\"Testing selesai\")\n",
    "print(matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d378c951-65d8-47f8-a422-a3c17238c379",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arange\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the training and validation loss dictionaries\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      5\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Retrieve each dictionary's values\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load' is not defined"
     ]
    }
   ],
   "source": [
    "from numpy import arange\n",
    " \n",
    "# Load the training and validation loss dictionaries\n",
    "train_loss = load(open('train_loss.pkl', 'rb'))\n",
    "val_loss = load(open('val_loss.pkl', 'rb'))\n",
    " \n",
    "# Retrieve each dictionary's values\n",
    "train_values = train_loss.values()\n",
    "val_values = val_loss.values()\n",
    " \n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, 21)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, train_values, label='Training Loss')\n",
    "plt.plot(epochs, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(arange(0, 21, 2))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd25ce1-c40a-4c39-b037-dca87bc0f33b",
   "metadata": {},
   "source": [
    "## K Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd0b2ce-d4bd-4ac6-954d-b09f8ede03a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18a9ed-02bd-4df0-9d5a-87dd398a3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "accuracies = []\n",
    "embed_dim = 100\n",
    "units = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a18a929-90ed-46f9-9ad4-905d839fb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate sebanyak k cross validation\n",
    "for iteration, data in enumerate(kf.split(X_train), start=1):\n",
    "\n",
    "    # get data and target train\n",
    "    data_train = X_train[data[0]]\n",
    "    target_train = y_train[data[0]]\n",
    "\n",
    "    # get data and target test\n",
    "    data_test =  X_train[data[1]]\n",
    "    target_test =  y_train[data[1]]\n",
    "\n",
    "    # model training menggunakan data train\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embed_dim))\n",
    "    model.add(SimpleRNN(units, dropout=0.2))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    sgd = optimizers.Adam(learning_rate= 0.001)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary)\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
    "    history = model.fit(data_train, target_train, epochs=10, batch_size=10, validation_data = (data_test, target_test), verbose=1, callbacks=[es])\n",
    "\n",
    "    # prediksi data test\n",
    "    predictions = model.predict(data_test)\n",
    "    y_pred = predictions\n",
    "\n",
    "    # menghitung accuracy\n",
    "    accuracy = accuracy_score(target_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "    print(\"Training ke-\", iteration)\n",
    "    print(classification_report(target_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "    print(\"=================================================================\")\n",
    "\n",
    "    accuracies.append(accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fefb30d-bf7f-4a59-84cb-5bab3cba1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(\"Rata-rata accuracy: \", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea68181-2ca9-4515-85ed-b5ce873f14f9",
   "metadata": {},
   "source": [
    "## Evaluation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33108a-7157-4b9a-967f-51aa447c4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.legend()\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e79bf-aec7-4a41-9957-7d8c7843cfb7",
   "metadata": {},
   "source": [
    "# Prediksi data baru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96dbea-407e-49f4-8079-5aa71f0b78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d75186-95ca-405d-85e6-86aa7577b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"Pelayanan baik, tempat parkir cukup luas\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eb425-1bb2-4437-8ebc-65edc9d4f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(sent):\n",
    "    string = sent.lower()\n",
    "    string = re.sub(r'[^a-zA-Z0-9]', ' ', string)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c2b399-b6fc-40e4-8eec-7817991316b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = ['negative','neutral','positive']\n",
    "\n",
    "text = [cleansing(input_text)]\n",
    "predicted = tokenizer.texts_to_sequences(text)\n",
    "guess = pad_sequences(predicted, maxlen=X.shape[1])\n",
    "\n",
    "model = load_model(\"model_rnn.keras\")\n",
    "prediction = model.predict(guess)\n",
    "polarity = np.argmax(prediction[0])\n",
    "\n",
    "print(\"Text: \", text[0])\n",
    "print(\"Sentiment: \", sentiment[polarity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f568659-f08e-45ea-a0eb-884a01208908",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"API/resources_of_rnn/x_pad_sequences.pickle\",'rb')\n",
    "feature_file_from_rnn = pickle.load(file)\n",
    "file = open(\"API/resources_of_rnn/tokenizer.pickle\",'rb')\n",
    "tokenizer_from_rnn = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "model_file_from_rnn = load_model('API/model_of_rnn/model_rnn.keras')\n",
    "\n",
    "original_text = \"Pelayanan baik, tempat parkir cukup luas\"\n",
    "text = [cleansing(original_text)]\n",
    "\n",
    "feature = tokenizer_from_rnn.texts_to_sequences(text)\n",
    "feature = pad_sequences(feature, maxlen=feature_file_from_rnn.shape[1])\n",
    "\n",
    "prediction = model_file_from_rnn.predict(feature)\n",
    "get_sentiment = sentiment[np.argmax(prediction[0])]\n",
    "\n",
    "get_sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
